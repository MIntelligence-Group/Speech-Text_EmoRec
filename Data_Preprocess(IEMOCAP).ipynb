{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####function for extracting speech features####\n",
    "\n",
    "def extract_feature(file_name, **kwargs):         \n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")            \n",
    "    chroma = kwargs.get(\"chroma\")        \n",
    "    mel = kwargs.get(\"mel\")              \n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        X = librosa.to_mono(X)\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:                         #getting the mfcc feature \n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "            \n",
    "        if chroma:                       #getting the chroma feature \n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:                          #getting MEL Spectrogram Frequency (mel) feature\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "            \n",
    "                                         #stacking three features in the variable called result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_EMOTIONS = {                 # available emotions set\n",
    "    \"Anger\",\n",
    "    \"Happiness\",\n",
    "    \"Neutra\",\n",
    "    \"Sadness\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R,q=[],[]\n",
    "count=0\n",
    "#importing speech modality\n",
    "\n",
    "for i in AVAILABLE_EMOTIONS:                   # made files of each of the four emotions for speech files\n",
    "    for file in sorted(glob.glob(i+\"/Ses01*.wav\")):        \n",
    "                                               #for every sound file in session 1 \n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True) #calling the extract feature function for speech features\n",
    "        count+=1                            #to count the number of files in session 1\n",
    "        R.append(features)                  #appending speech features for every audio in list R \n",
    "        p=re.split(\"/\", file, 1)            \n",
    "        p.reverse()\n",
    "        q.append(p)                         #q is storing the respective emotion for each sound file\n",
    "        \n",
    "        \n",
    "    for file in sorted(glob.glob(i+\"/Ses02*.wav\")):    #for every sound file in session 2  \n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        count+=1\n",
    "        R.append(features)\n",
    "        p=re.split(\"/\", file, 1)\n",
    "        p.reverse()\n",
    "        q.append(p)\n",
    "        \n",
    "print(count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=np.array(R)                       #converting list into numpy array\n",
    "q=np.array(q)                       #converting list into numpy array\n",
    "R=R.astype('float32')      \n",
    "q[q=='Anger']=0                     # numbering the respective emotions 0,1,2,3\n",
    "q[q=='Happiness']=1\n",
    "q[q=='Sadness']=2\n",
    "q[q=='Neutra']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate((q,R), axis=1)  # concatenating the columns q and R to feed both speech and text features simultaneously to the model\n",
    "li=arr.tolist()                      # converting arr to list to sort (easy to sort using a list)\n",
    "li=sorted(li)                        #sorting the list on the basis of q value\n",
    "li=np.array(li) \n",
    "\n",
    "l=li[:,1]                           #getting the label(labels are emotions) vector l using li array\n",
    "M=li[:,2:]                          #getting the speech feature matrix M using li array\n",
    "l=l.astype('int64') \n",
    "M=M.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####function for extracting text features####\n",
    "\n",
    "#text features for each text file for session1 (doing it for all 10 emotions, will take the 4 emotions in later part)\n",
    "\n",
    "y=[]\n",
    "for i in range(1,9): \n",
    "    for file in glob.glob(\"Ses01F_impro0\"+str(i)+\".txt\"):     #for every text file starting with Ses01F_impro0\n",
    "        f = open(file)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            x = re.search(\"^Ses0\", line)                #getting file name and corresponding text for each file \n",
    "            if(x==None):\n",
    "                continue\n",
    "            p = re.split(\"\\s\", line, 2)                 \n",
    "            del(p[1])                                  # deleting useless information in the list p\n",
    "            y.append(p)                                # appending the file name and corresponding text in list 'p' of every audio file in y\n",
    "for i in range(1,9): \n",
    "    for file in glob.glob(\"Ses01M_impro0\"+str(i)+\".txt\"):    #for every text file starting with Ses01M_impro0\n",
    "        f = open(file)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            x = re.search(\"^Ses0\", line)\n",
    "            if(x==None):\n",
    "                continue\n",
    "            p = re.split(\"\\s\", line, 2)\n",
    "            del(p[1])\n",
    "            y.append(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session2\n",
    "#text features for each text file for session2 (same as above)\n",
    "for i in range(1,9): \n",
    "    for file in glob.glob(\"Ses02F_impro0\"+str(i)+\".txt\"):\n",
    "        f = open(file)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            x = re.search(\"^Ses0\", line)\n",
    "            if(x==None):\n",
    "                continue\n",
    "            p = re.split(\"\\s\", line, 2)\n",
    "            del(p[1])\n",
    "            y.append(p)\n",
    "for i in range(1,9): \n",
    "    for file in glob.glob(\"Ses02M_impro0\"+str(i)+\".txt\"):\n",
    "        f = open(file)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            x = re.search(\"^Ses0\", line)\n",
    "            if(x==None):\n",
    "                continue\n",
    "            p = re.split(\"\\s\", line, 2)\n",
    "            del(p[1])\n",
    "            y.append(p)    \n",
    "#y contain file name and corresponding text for every audio files in session 1 and 2 (all 10 emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))\n",
    "x=sorted(y)\n",
    "# sorting the text on the basis of file name\n",
    "# x will contain file name and corresponding text, sorted according to file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_EMO = {\n",
    "    \"Anger\",\n",
    "    \"Happiness\",\n",
    "    \"Neutra\",\n",
    "    \"Sadness\",\n",
    "    \"Other\",\n",
    "    \"Surprise\",\n",
    "    \"Disgust\",\n",
    "    \"Fear\",\n",
    "    \"Excited\",\n",
    "    \"Frustration\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "# looping again across all 10 emotions to get the desired file name and corresponding emotions\n",
    "for i in AVAILABLE_EMO:\n",
    "    for file in sorted(glob.glob(str(i)+\"/Ses01*.wav\")):   #again using the speech file \n",
    "        p=re.split(\"/\", file, 2)\n",
    "        p.reverse()\n",
    "        p[0]=p[0][:-4]\n",
    "        y.append(p)\n",
    "for i in AVAILABLE_EMO:\n",
    "    for file in sorted(glob.glob(str(i)+\"/Ses02*.wav\")):\n",
    "        p=re.split(\"/\", file, 2)\n",
    "        p.reverse()\n",
    "        p[0]=p[0][:-4]\n",
    "        print(p)\n",
    "        y.append(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sorted(y)\n",
    "import numpy as np\n",
    "X=np.array(x)\n",
    "Y=np.array(y)\n",
    "X=X[:,1]\n",
    "Y=Y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=[],[]\n",
    "count=0\n",
    "EMOT = {\n",
    "    \"Anger\",\n",
    "    \"Happiness\",\n",
    "    \"Neutra\",\n",
    "    \"Sadness\"\n",
    "}\n",
    "for i in range(0,1547):\n",
    "    if Y[i] in EMOT:\n",
    "        x.append(X[i])\n",
    "        y.append(Y[i])\n",
    "        count+=1\n",
    "\n",
    "y=np.array(y)\n",
    "x=np.array(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "stopwords_list = stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 100000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "VAL_SIZE = 1000  # Size of the validation set\n",
    "NB_START_EPOCHS = 18  # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\n",
    "MAX_LEN = 20  # Maximum number of words in a sequence\n",
    "GLOVE_DIM = 50# Number of dimensions of the GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.' + str(GLOVE_DIM) + 'd.txt'\n",
    "f='glove.6B/'\n",
    "emb_dict = {}\n",
    "glove = open(f+glove_file)\n",
    "for line in glove:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    emb_dict[word] = vector\n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(x)\n",
    "\n",
    "x_train_seq = tk.texts_to_sequences(x)\n",
    "\n",
    "x_train_seq_trunc = pad_sequences(x_train_seq, maxlen=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.zeros((NB_WORDS, GLOVE_DIM))\n",
    "\n",
    "for w, i in tk.word_index.items():\n",
    "    # The word_index contains a token for all words of the training data so we need to limit that\n",
    "    if i < NB_WORDS:\n",
    "        vect = emb_dict.get(w)\n",
    "        # Check if the word from the training data occurs in the GloVe word embeddings\n",
    "        # Otherwise the vector is kept with only zeros\n",
    "        if vect is not None:\n",
    "            emb_matrix[i] = vect\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(input_text):\n",
    "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = input_text.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    x[i]=remove_stopwords(x[i])\n",
    "    x[i]= porter.stem(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y=='Anger']=0\n",
    "y[y=='Happiness']=1\n",
    "y[y=='Sadness']=2\n",
    "y[y=='Neutra']=3\n",
    "y=y.astype('int64') \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the text features, x_train_seq contains the processed text feature vector and y contains \n",
    "##  the respective emotions\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_seq_trunc,y,test_size=0.25,random_state=4)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting the speech features, x_train_seq contains the processed speech feature vector and l contains \n",
    "##  the respective emotions\n",
    "M_train, M_test, l_train, l_test = train_test_split(M,l,test_size=0.25,random_state=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
